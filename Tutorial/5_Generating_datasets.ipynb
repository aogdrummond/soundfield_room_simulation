{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "019dfd8b",
   "metadata": {},
   "source": [
    "#### Import required libraries and set path to main directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ef1d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path(os.getcwd()).parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0435bec3",
   "metadata": {},
   "source": [
    "#### Import required function to generate the room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738aa5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Core.dataset_creation import create_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8653986d",
   "metadata": {},
   "source": [
    "#  Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2f4539",
   "metadata": {},
   "source": [
    "### 1 - Samples generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1706b456",
   "metadata": {},
   "source": [
    "### Set dataset features\n",
    "- geometry[str]: \"rectangular\" or \"general\", whether it is for rectangular or nonretangular rooms to be generated.\n",
    "- dataset_path[str]: A string with the path where the dataset will be saved\n",
    "- n_samples[int]: number of samples of the dataset (number of the samples on the folder to stop execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5160b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry= \"rectangular\"\n",
    "dataset_path = r\"D:\\DL_Datasets\\TCC_Files_Generation\\datasets\\new_rectangular_dataset\"\n",
    "n_samples = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9777bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset(geometry=geometry,\n",
    "               dataset_path=dataset_path,\n",
    "               n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e111bc",
   "metadata": {},
   "source": [
    "### 2 - train-val-test Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fb9f28",
   "metadata": {},
   "source": [
    "Import required tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb8f848",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Core.dataset_splitting import split_dataset, split_dataset_subfolders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d83b2a",
   "metadata": {},
   "source": [
    "#### Insert required parameters:\n",
    "\n",
    "* dataset_path [str]: the root path for the directory storing the dataset.\n",
    "- prop [float]: the proportion of data used as training set. The remaining samples will be used half as validation and half as training set (i.e. prop = 0.7 is 70% training set, 15% val and 15% test).\n",
    "* n_files [int]: number of .mat files in root dir transfered to dataset to be used. By default all the samples are transfered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9529cca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r\"D:\\DL_Datasets\\TCC_Files_Generation\\datasets\\new_rectangular_dataset\"\n",
    "prop = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1601a9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset(dataset_path=dataset_path,\n",
    "              prop=prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33e0c22",
   "metadata": {},
   "source": [
    "### 3 - Subfolder splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6b8adb",
   "metadata": {},
   "source": [
    "In the cases when large sets are build (containing thousands of samples) the system may present performance issues when looking for the file inside the folder. For this reasons it is recommended to split again each set into subfolders, which is provided by the following function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962a5f76",
   "metadata": {},
   "source": [
    "#### Insert parameters:\n",
    "\n",
    "* dataset_path [str]: root dir for directory. Same as used in the function above\n",
    "- n_files_sf [int]: number of files contained on each subfolder. Anything below 1000 should be enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537b72ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_files_sf = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c74452",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset_subfolders(dataset_path=dataset_path,\n",
    "                         n_files_sf=n_files_sf)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c3d61f5d0a6b79d36d9ba68feec92d88d2ac8c605b8be456282bc1636e81936"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
